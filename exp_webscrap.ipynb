{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: dwh-siloam\n",
      "Region: asia-southeast1\n",
      "Checking Credentials...\n",
      "Using service account credentials from service_account folder\n",
      "Using service account file: c:\\Others\\chatbot-llm\\service_account\\dwh-siloam-99402e61edd2.json\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'dwh-siloam'\n",
    "REGION = 'asia-southeast1'\n",
    "print(f\"Project ID: {PROJECT_ID}\\nRegion: {REGION}\")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "from pathlib import Path\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "print(f\"Checking Credentials...\")\n",
    "if not any((Path.cwd()/\"service_account\").glob('*.json')):\n",
    "    print(\"Service account folder is empty. Fallback using default gcloud account\")\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "else:\n",
    "    print('Using service account credentials from service_account folder')\n",
    "    from google.oauth2 import service_account\n",
    "    sa_file = list((Path.cwd()/\"service_account\").glob('*.json'))[0]\n",
    "    print(f\"Using service account file: {sa_file}\")\n",
    "    credentials = service_account.Credentials.from_service_account_file(sa_file)\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "\n",
    "# Import libraries\n",
    "from langchain_google_vertexai import VertexAI, ChatVertexAI, create_structured_runnable\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import requests\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from settings import CopilotSettings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CopilotSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\envs\\chatai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scrapegraphai.graphs import SmartScraperGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBz4zKLnsR1vZ6JWhtwSV68qpZ8ZOp0g0I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# GOOGLE_APIKEY = \"YOUR_API_KEY\"\n",
    "\n",
    "# Define the configuration for the graph\n",
    "graph_config = {\n",
    "    \"llm\": {\n",
    "        # \"api_key\": os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        \"model\": \"gemini-pro\",\n",
    "    },\n",
    "    \"embedding\": {\n",
    "        \"model\": \"textembedding-gecko-multilingual@latest\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Embedding Model missing or not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the SmartScraperGraph instance\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m smart_scraper_graph \u001b[38;5;241m=\u001b[39m \u001b[43mSmartScraperGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mList me all the articles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://perinim.github.io/projects\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_config\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\chatai\\lib\\site-packages\\scrapegraphai\\graphs\\smart_scraper_graph.py:47\u001b[0m, in \u001b[0;36mSmartScraperGraph.__init__\u001b[1;34m(self, prompt, source, config)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, source: \u001b[38;5;28mstr\u001b[39m, config: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\chatai\\lib\\site-packages\\scrapegraphai\\graphs\\abstract_graph.py:50\u001b[0m, in \u001b[0;36mAbstractGraph.__init__\u001b[1;34m(self, prompt, config, source)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_llm(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm\u001b[39m\u001b[38;5;124m\"\u001b[39m], chat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_default_embedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m    \u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_embedder(\n\u001b[0;32m     52\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Set common configuration parameters\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\miniconda3\\envs\\chatai\\lib\\site-packages\\scrapegraphai\\graphs\\abstract_graph.py:210\u001b[0m, in \u001b[0;36mAbstractGraph._create_default_embedder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BedrockEmbeddings(client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_model\u001b[38;5;241m.\u001b[39mmodel_id)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding Model missing or not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Embedding Model missing or not supported"
     ]
    }
   ],
   "source": [
    "# Create the SmartScraperGraph instance\n",
    "smart_scraper_graph = SmartScraperGraph(\n",
    "    prompt=\"List me all the articles\",\n",
    "    source=\"https://perinim.github.io/projects\",\n",
    "    config=graph_config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
