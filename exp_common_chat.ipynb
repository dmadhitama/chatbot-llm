{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: dwh-siloam\n",
      "Region: asia-southeast1\n",
      "Checking Credentials...\n",
      "Using service account credentials from service_account folder\n",
      "Using service account file: /Users/donnymirzaadhitama/workspace/others/chatbot-llm/service_account/dwh-siloam-99402e61edd2.json\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'dwh-siloam'\n",
    "REGION = 'asia-southeast1'\n",
    "print(f\"Project ID: {PROJECT_ID}\\nRegion: {REGION}\")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "from pathlib import Path\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "print(f\"Checking Credentials...\")\n",
    "if not any((Path.cwd()/\"service_account\").glob('*.json')):\n",
    "    print(\"Service account folder is empty. Fallback using default gcloud account\")\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "else:\n",
    "    print('Using service account credentials from service_account folder')\n",
    "    from google.oauth2 import service_account\n",
    "    sa_file = list((Path.cwd()/\"service_account\").glob('*.json'))[0]\n",
    "    print(f\"Using service account file: {sa_file}\")\n",
    "    credentials = service_account.Credentials.from_service_account_file(sa_file)\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "\n",
    "# Import libraries\n",
    "from langchain_google_vertexai import VertexAI, ChatVertexAI, create_structured_runnable\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from typing import List, Optional\n",
    "import requests\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from settings import CopilotSettings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CopilotSettings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model & prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VertexAI(\n",
    "    model_name=config.GCP_AGENT_MODEL_NAME, \n",
    "    temperature=0, \n",
    "    max_output_tokens=8192\n",
    ")\n",
    "# chat_llm = ChatVertexAI(\n",
    "#     model_name=config.GCP_AGENT_MODEL_NAME, \n",
    "#     convert_system_message_to_human=True, \n",
    "#     temperature=0, \n",
    "#     max_output_tokens=8192\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question below using Indonesian language.\n",
    "Do not make any assumptions. If you don't know the answer, just answer that you don't know.\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Maaf, saya tidak tahu makanan kesukaan Anda.\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"question\": \"Apa makanan kesukaanku?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a conversation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question below using Indonesian language.\n",
    "Do not make any assumptions. If you don't know the answer, just answer that you don't know.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_message\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"message\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    AIMessage(\n",
    "        content=\"Halo, apa kabar?\",\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Baik.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Ada yang bisa saya bantu?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "query = HumanMessage(\n",
    "    content=\"Siapa nama presiden Indonesia tahun 2025?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Halo, apa kabar?'),\n",
       " HumanMessage(content='Baik.'),\n",
       " AIMessage(content='Ada yang bisa saya bantu?'),\n",
       " HumanMessage(content='Siapa nama presiden Indonesia tahun 2025?')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(query)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Maaf, saya tidak dapat menjawab pertanyaan tersebut karena pengetahuan saya terbatas hingga April 2023. Untuk informasi terkini, saya sarankan Anda untuk memeriksa situs web resmi pemerintah Indonesia atau sumber berita yang terpercaya.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"message\": messages})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = response.split(\"AI:\")[-1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start FU conversation here\n",
    "Every you asked different question, edit `fu_query` variable. And run the cell below again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Maaf, pengetahuan saya terbatas hingga April 2023. Untuk informasi terkini, saya sarankan Anda untuk memeriksa situs web resmi pemerintah Indonesia atau sumber berita yang terpercaya.\n",
      "Elapsed time: 1.435 [sec]\n"
     ]
    }
   ],
   "source": [
    "fu_query = \"Jadi siapakah yang menang pemilu pilpres kemarin?\"\n",
    "response = {\"question\":\"apa itu...\", \"chat_history\":[]}\n",
    "start = time.time()\n",
    "answer = AIMessage(\n",
    "    content=answer\n",
    ")\n",
    "query = HumanMessage(\n",
    "    content=fu_query\n",
    ")\n",
    "messages.append(answer)\n",
    "messages.append(query)\n",
    "\n",
    "response = chain.invoke({\"message\": messages})\n",
    "if \"AI:\" in response:\n",
    "    answer = response.split(\"AI:\")[-1].strip()\n",
    "else:\n",
    "    answer = response\n",
    "print(response)\n",
    "print(\"Elapsed time:\", round(time.time() - start, 3), \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the question history here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
