{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: dwh-siloam\n",
      "Region: asia-southeast1\n",
      "Checking Credentials...\n",
      "Using service account credentials from service_account folder\n",
      "Using service account file: c:\\Others\\chatbot-llm\\service_account\\dwh-siloam-99402e61edd2.json\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'dwh-siloam'\n",
    "REGION = 'asia-southeast1'\n",
    "print(f\"Project ID: {PROJECT_ID}\\nRegion: {REGION}\")\n",
    "\n",
    "# Initialize Vertex AI\n",
    "from pathlib import Path\n",
    "import vertexai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "print(f\"Checking Credentials...\")\n",
    "if not any((Path.cwd()/\"service_account\").glob('*.json')):\n",
    "    print(\"Service account folder is empty. Fallback using default gcloud account\")\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "else:\n",
    "    print('Using service account credentials from service_account folder')\n",
    "    from google.oauth2 import service_account\n",
    "    sa_file = list((Path.cwd()/\"service_account\").glob('*.json'))[0]\n",
    "    print(f\"Using service account file: {sa_file}\")\n",
    "    credentials = service_account.Credentials.from_service_account_file(sa_file)\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "    vertexai.init(project=PROJECT_ID, location=REGION, credentials=credentials)\n",
    "\n",
    "# Import libraries\n",
    "from langchain_google_vertexai import VertexAI, ChatVertexAI, create_structured_runnable\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from settings import CopilotSettings\n",
    "import time\n",
    "\n",
    "config = CopilotSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VertexAI(\n",
    "    model_name=config.GCP_AGENT_MODEL_NAME, \n",
    "    temperature=0, \n",
    "    max_output_tokens=8192\n",
    ")\n",
    "# chat_llm = ChatVertexAI(\n",
    "#     model_name=config.GCP_AGENT_MODEL_NAME, \n",
    "#     convert_system_message_to_human=True, \n",
    "#     temperature=0, \n",
    "#     max_output_tokens=8192\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question below using Indonesian language.\n",
    "Do not make any assumptions. If you don't know the answer, just answer that you don't know.\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maaf, saya tidak dapat menjawab pertanyaan Anda karena saya tidak memiliki informasi tentang makanan kesukaan Anda. Saya hanya dapat membantu Anda dengan pertanyaan yang berkaitan dengan informasi umum atau tugas yang dapat saya selesaikan dengan kemampuan saya saat ini. \n",
      "\n",
      "Apakah ada pertanyaan lain yang dapat saya bantu?\n"
     ]
    }
   ],
   "source": [
    "chain = (\n",
    "    prompt\n",
    "    | chat_llm\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"question\": \"Apa makanan kesukaanku?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a conversation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question below using Indonesian language.\n",
    "Do not make any assumptions. If you don't know the answer, just answer that you don't know.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_message\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"message\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    AIMessage(\n",
    "        content=\"Halo, apa kabar?\",\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Baik.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Ada yang bisa saya bantu?\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "query = HumanMessage(\n",
    "    content=\"Apa makanan kesukaanku?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Halo, apa kabar?'),\n",
       " HumanMessage(content='Baik.'),\n",
       " AIMessage(content='Ada yang bisa saya bantu?'),\n",
       " HumanMessage(content='Apa makanan kesukaanku?')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(query)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"message\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maaf, saya tidak bisa menjawab pertanyaan itu karena saya tidak memiliki informasi tentang makanan kesukaan Anda.\n"
     ]
    }
   ],
   "source": [
    "answer = response.split(\"AI:\")[-1].strip()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start FU conversation here\n",
    "Every you asked different question, edit `fu_query` variable. And run the cell below again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI: Penggunaan micin atau monosodium glutamat (MSG) dalam masakan soto ayam tergantung pada selera masing-masing orang. Micin merupakan penyedap rasa yang dapat membuat masakan menjadi lebih gurih dan lezat. Namun, penggunaan micin yang berlebihan dapat berdampak buruk bagi kesehatan. Oleh karena itu, sebaiknya gunakan micin dalam jumlah yang wajar dan tidak berlebihan.\n",
      "Elapsed time: 1.865 [sec]\n"
     ]
    }
   ],
   "source": [
    "fu_query = \"Apakah perlu micin?\"\n",
    "\n",
    "start = time.time()\n",
    "answer = AIMessage(\n",
    "    content=answer\n",
    ")\n",
    "query = HumanMessage(\n",
    "    content=fu_query\n",
    ")\n",
    "messages.append(answer)\n",
    "messages.append(query)\n",
    "\n",
    "response = chain.invoke({\"message\": messages})\n",
    "if \"AI:\" in response:\n",
    "    answer = response.split(\"AI:\")[-1].strip()\n",
    "else:\n",
    "    answer = response\n",
    "print(response)\n",
    "print(\"Elapsed time:\", round(time.time() - start, 3), \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the question history here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
